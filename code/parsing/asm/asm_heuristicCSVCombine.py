__author__ = "Cody Wild"

"""
This code implements heuristic stemming (i.e. canonicalizing something like loc_1243 into loc_) using regular expressions on already parsed data
to reduce its dimensionality and size even further.
"""

from ast import literal_eval
import csv
import random
import re
import csv
import json
import pandas as pd
if __name__ == "__main__":
    columnDict = {}
    columnCounter = 0

    for dSet in ['test', 'train']:
        fileName = '/Users/codywild/Desktop/MSAN/Module3/AdvancedML/KaggleMicrosoftMalware/data/' + dSet + "_simpleASM.txt"
        f = open(fileName, "r")
        #internal counter
        i = 0
        #num-files counter
        j = 0
        #list of dictionaries containing column names: values
        bigList = []
        fieldVals = set(["fileName"])
        print "Beginning " + dSet
        for line in f:
            bigList.append({})
            tup = literal_eval(line)
            fileNameMatch = re.match('.*:\/\/.*\/(\w+).asm', tup[0])
            if fileNameMatch:
                fileName = fileNameMatch.groups(1)[0]
            else:
                fileName = "error"
                print "FILE NAME ERROR"
                print tup[0]
                exit(0)

            bigList[i]["fileName"] = fileName

            #for word, frequency in list of (word, frequency)
            for innerTup in tup[1]:
                #multi-word indicator
                words = False
                word = innerTup[0]
                count = innerTup[1]
                numberMatch = re.match('[0-9A-F]+h', word)
                bracketMatch = re.match('\[(\w{3}).*\]', word)
                dWordMatch = re.match('dword\_.*', word)
                subMatch = re.match('sub\_.*', word)
                locMatch = re.match('loc\_.*', word)
                offMatch = re.match('off\_.*', word)
                byteMatch = re.match('byte\_.*', word)
                unkMatch = re.match('unk\_.*', word)
                locRetMatch = re.match('locret\_.*', word)
                wordMatch = re.match('word\_.*', word )
                dupMatch = re.match('dup\(.*\)', word)


                qMarkMatch = re.match('\?(\w*)@.*', word)
                doubleColMatch = re.match('(\w*)::(\w*)\(\w*', word)

                if not numberMatch:
                    if dupMatch:
                        word = "dup"
                    elif wordMatch:
                        word = "word_"
                    elif locRetMatch:
                        word = "locret_"
                    elif unkMatch:
                        word = "unk_"
                    elif byteMatch:
                        word = "byte_"
                    elif dWordMatch:
                        word = "dword_"
                    elif subMatch:
                        word = "sub_"
                    elif locMatch:
                        word = "loc_"
                    elif offMatch:
                        word = "off_"

                    elif bracketMatch:
                        word = '[' + bracketMatch.groups(1)[0] + ']'
                    elif qMarkMatch:
                        word = qMarkMatch.groups(1)[0]
                    elif doubleColMatch:
                        words = True
                        word = [doubleColMatch.groups(1)[0], doubleColMatch.groups(1)[1]]

                    if words:
                        for singWord in word:
                            if singWord not in columnDict:
                                columnDict[singWord] = str(columnCounter)
                                columnCounter += 1
                            bigList[i][columnDict[singWord]] = count
                            fieldVals.add(columnDict[singWord])
                    else:
                        if word not in columnDict:
                            columnDict[word] = str(columnCounter)
                            columnCounter += 1
                        bigList[i][columnDict[word]] = count
                        fieldVals.add(columnDict[word])

            i += 1
            print i
            if i % 500 == 0:
                csvFileName = '/Users/codywild/Desktop/MSAN/Module3/AdvancedML/KaggleMicrosoftMalware/data/' + dSet + 'SimpleASM-CSV/' + dSet +'SimpleASM_' + str(j).zfill(2) + '.csv'
                with open(csvFileName, 'w') as outputFullFile:
                    dict_writer2 = csv.DictWriter(outputFullFile, fieldVals)
                    dict_writer2.writeheader()
                    dict_writer2.writerows(bigList)
                print str(j) + "CSV Completed "
                bigList = []
                fieldVals = set(["fileName"])
                j += 1
                i = 0
                with open('columnKey.json', 'wb') as g:
                    json.dump(columnDict, g)
                print "JSON Updated"
                print str(len(columnDict)) + " Columns so far"


        csvFileName ='/Users/codywild/Desktop/MSAN/Module3/AdvancedML/KaggleMicrosoftMalware/data/' + dSet + 'SimpleASM-CSV/' + dSet +'SimpleASM_' + str(j).zfill(2) + '.csv'
        with open(csvFileName, 'w') as outputFullFile:
            dict_writer2 = csv.DictWriter(outputFullFile, fieldVals)
            dict_writer2.writeheader()
            dict_writer2.writerows(bigList)
        print "Last CSV Completed "
        print dSet + " Completed"
