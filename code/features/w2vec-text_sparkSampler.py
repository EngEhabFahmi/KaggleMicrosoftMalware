__author__ = "Cody Wild"

"""
This Spark parser was used on the full dataset to pull a sample of 'sentences' - i.e. internally coherent units from within the _text 
(i.e. typical assembley code) code section of the .asm file. This 50% sample - stored in the form of a list of lists of tokens 
- was then used to train a Word2Vec model specific to the _text section
"""
import re
import random
from pyspark import SparkContext
#from pyspark import SparkContext

def sentenceParse(fileStr, section='text', type="tup"):
    if section == 'text':
        startTrigger = "_text"
    triggered = False
    sentenceTokens = []
    listOfSentences = []
    i = 0
    if type == "tup":
        fileList = fileStr[1].split('\n')
    elif type == "list":
        fileList = fileStr
    elif type == "str":
        fileList = fileStr.split('\n')

    for line in fileList:
        if startTrigger in line:
            triggered = True
        if triggered:
            matchObj = re.match('\.text:[\dA-Z]+\s*(?:[A-F0-9]{2}\s)*\s*;?(.*);?', line)
            endOfSentMatch = re.match('\.text:[\dA-Z]+\s*; -+', line)
            endOfSentMatch2 = re.match('\.text:[\dA-Z].*loc_.*:.\s*; CODE XREF.*', line)
            stillInSectionMatch = re.match('\.text:.*', line)
            endOfSubroutineMatch = re.match('\.text:[\dA-Z]+\s*; [= SUBROUTINE]*', line)
            ddLineMatch = re.match('\.text:[\dA-Z]+\s*(?:[A-F0-9]{2}\s)*\s*.*dd\s(?:[A-F0-9]*h[,|\s]*)*.*', line)

            if not stillInSectionMatch:
                continue
            if endOfSubroutineMatch or endOfSentMatch or endOfSentMatch2:
                if '_text' in sentenceTokens:
                    sentenceTokens.remove('_text')
                if sentenceTokens:
                    listOfSentences.append(sentenceTokens)
                sentenceTokens = []
                continue
            if matchObj and not ddLineMatch:
                words = matchObj.groups(1)[0].split()
                for word in words:
                    bracketMatch = re.match('\[(\w{3}).*\]', word)
                    dWordMatch = re.match('dword\_.*', word)
                    subMatch = re.match('sub\_.*', word)
                    locMatch = re.match('loc\_.*', word)
                    offMatch = re.match('off\_.*', word)
                    byteMatch = re.match('byte\_.*', word)
                    unkMatch = re.match('unk\_.*', word)
                    locRetMatch = re.match('locret\_.*', word)
                    wordMatch = re.match('word\_.*', word )
                    dupMatch = re.match('dup\(.*\)', word)
                    if dupMatch:
                        word = "dup"
                    elif wordMatch:
                        word = "word_"
                    elif locRetMatch:
                        word = "locret_"
                    elif unkMatch:
                        word = "unk_"
                    elif byteMatch:
                        word = "byte_"
                    elif dWordMatch:
                        word = "dword_"
                    elif subMatch:
                        word = "sub_"
                    elif locMatch:
                        word = "loc_"
                    elif offMatch:
                        word = "off_"
                    elif bracketMatch:
                        word = '[' + bracketMatch.groups(1)[0] + ']'
                    sentenceTokens.append(word)
    return listOfSentences

def stringType(s):
    if isinstance(s, str):
        return "ascii"
    elif isinstance(s, unicode):
        return "unicode"
    else:
        return "other"




if __name__ == "__main__":
    sc = SparkContext()
    #fileStr = f.readlines()
    # f.close()

    sc.wholeTextFiles("s3n://malwaredata/train/*.asm", 4000)\
         .sample(False, 0.15)\
         .flatMap(sentenceParse).coalesce(100).saveAsTextFile("s3n://malwaredata/stemmedSentenceText_" + str(round(random.random(), 2)))

    #sc.wholeTextFiles("file:///Users/codywild/Desktop/MSAN/Module3/AdvancedML/KaggleMicrosoftMalware/dataSample/*.asm", 4)\
    #    .flatMap(sentenceParse).saveAsTextFile("file:///Users/codywild/Desktop/MSAN/Module3/AdvancedML/KaggleMicrosoftMalware/dataSample/smallSample")
    # flattened = codeCorpus.flatMap(sentenceParse)
    # print flattened.take(1)
    #codeCorpus.saveAsTextFile("file:///Users/codywild/Desktop/MSAN/Module3/AdvancedML/KaggleMicrosoftMalware/dataSample/sentenceSample")

