import re
import random
import pandas as pd
import re
from pyspark import SparkContext
from fileinput import input
from glob import glob
from boto.s3.connection import S3Connection
def asmReduce(a, b):
    #(frequency_counter, section_length, num_subroutines, totalNumTokens)
    totalFreqDict = {}
    aKeys = set(a[0].keys())
    bKeys =set(b[0].keys())
    intersectKeys = aKeys.intersection(bKeys)
    onlyA = aKeys.difference(intersectKeys)
    onlyB = bKeys.difference(intersectKeys)
    for key in intersectKeys:
       totalFreqDict[key] = a[0][key] + b[0][key]
    for key in onlyA:
       totalFreqDict[key] = a[0][key]
    for key in onlyB:
       totalFreqDict[key] = b[0][key]
    meanDict = {}
    aKeys2 = set(a[1].keys())
    bKeys2 = set(b[1].keys())
    intersectKeys2 = aKeys2.intersection(bKeys2)
    onlyA2 = aKeys2.difference(intersectKeys2)
    onlyB2 = bKeys2.difference(intersectKeys2)
    for key in intersectKeys2:
        aVal = a[1][key]
        bVal = b[1][key]
        meanDict[key] = (aVal+bVal)/2.0
    for key in onlyA2:
        meanDict[key] = a[1][key]
    for key in onlyB2:
        meanDict[key] = b[1][key]
    avgNumSubroutines = (a[2]+b[2])/2.0
    totalNumTokens = a[3] + b[3]
    return totalFreqDict, meanDict, avgNumSubroutines, totalNumTokens


if __name__ == "__main__":
    sc = SparkContext()
    asmAlmostReduced = sc.textFile("file:///Users/codywild/Desktop/MSAN/Module3/AdvancedML/KaggleMicrosoftMalware/AggSquared/*.txt", 10)
    print asmAlmostReduced.count()


