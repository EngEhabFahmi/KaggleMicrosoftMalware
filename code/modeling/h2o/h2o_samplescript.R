########################################################################################################
# SET UP
########################################################################################################

# install.pac kages("h2o")  # NEEDS THE VERY LATEST VERSION, 
                            # BEST TO DOWNLOAD ZIP FROM SITE & INSTALL FROM ZIP
                            # http://h2o.ai/download/
library(h2o)
ec2H2O <- h2o.init(ip = '00.00.00.000', port =54321) # CHANGE THIS BASED ON AWS EC2 INSTANCE
pathToData <- "https://s3-us-west-2.amazonaws.com/location/filname.txt"
filename.hex <- h2o.importFile(ec2H2O, path = pathToData, key = "filename.hex")


########################################################################################################
# AGGREGATE PLOT
########################################################################################################

classCounts <- as.data.frame(h2o.table(filename.hex["Class"]))
names(classCounts) <- c("class", "count")
ggplot(classCounts) + 
  geom_bar(aes(x=factor(class), y=count, fill=class), stat="identity") + 
  guides(fill=FALSE) + 
  ggtitle("Number of Files by Class") + xlab("Class") + ylab("Count")


########################################################################################################
# MODEL BUILDING
########################################################################################################

# Train/Test Split
s <- h2o.runif(merged.hex)
merged.train <- merged.hex[s <= 0.8,]
merged.train <- h2o.assign(merged.train, "merged.train")
merged.test <- merged.hex[s > 0.8,]
merged.test <- h2o.assign(merged.test, "merged.test")

# Random Forest Training
xs <- colnames(filename.hex)[-1] # vector of all feature names
merged.rf <- h2o.randomForest(y = "virus", x = xs, 
                             data = merged.train, 
                             ntree = 500, depth = 10000)

# Radom Forest Testing 
merged.rf.pred <- h2o.predict(merged.rf, merged.test[xs])
h2o.confusionMatrix(merged.rf.pred[,1], merged.test["virus"])


# Deep Learning Training
merged.dl <- h2o.deeplearning(y = "virus", x = xs, 
                     data = merged.train, 
                     hidden = c(100, 200),
                     epochs = 5)

# Deep Learning Testing
merged.dl.pred <- h2o.predict(merged.dl, merged.test[xs])
h2o.confusionMatrix(merged.dl.pred[,1], merged.test["virus"])


########################################################################################################
# GGPLOT2 CONFUSION MATRICES
########################################################################################################

DLCM <- h2o.confusionMatrix(merged.dl.pred[,1], merged.test["virus"])

actualTotal <- apply(DLCM[c(1:9),c(1:9)], 1, sum)
predictedTotal <- apply(DLCM[c(1:9),c(1:9)], 2, sum)
DLCMmelt <- as.data.frame(melt(DLCM[c(1:9),c(1:9)]))
DLCMmelt$actualCount <- rep(actualTotal)
DLCMmelt$ofactual <- DLCMmelt$value/DLCMmelt$actualCount

ggplot(data=DLCMmelt) +
  geom_tile(aes(x=Actual, y=Predicted, fill=ofactual),
            color="black", size=0.1) +
  labs(x="Actual",y="Predicted") + 
  geom_text(aes(x=Actual,y=Predicted, 
                label=sprintf("%.2f", ofactual)),
            size=3, colour="black") +
  scale_fill_gradient(low="grey",high="red") 


########################################################################################################
# LOG LOSS CALCULATION
########################################################################################################

loglossCalc <- function(actual, predicted) {
    # takes as input a vector of actual labels
    #   and an h2o.predict returned object
    # returns a logloss value
  N <- length(actual)
  pred <- as.data.frame(predicted)
  pred$actual <- actual
  pred$ylogp <- apply(dl.pred,1, function(x) 1*log(x[[x[1]+1]]))
  logloss <- -1/N*sum(dl.pred$ylogp)
  return(logloss)  
}

loglossCalc(actual=as.data.frame(merged.test["virus"])[[1]],
            predicted=merged.rf.pred)


