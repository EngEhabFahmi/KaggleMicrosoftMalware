__author__ = 'David Reilly'
from pyspark import SparkContext, SparkConf
from pyspark.mllib.regression import LabeledPoint
from pyspark.mllib.classification import LogisticRegressionWithSGD
from pyspark.mllib.tree import DecisionTree, RandomForest
import urllib2
import csv

## Replace empty strings with 0
def add_zeros_list(list):

    for i, j in enumerate(list):
        if j == '':
            list[i] = 0.0
        else:
            try:
                list[i] = float(j)
            except ValueError:
                list[i] = str(j)

    return list

## Split CSV to RDD
def split_csv(rdd):

    return rdd.map(lambda x: x.split(","))

## Map add_zeros_list
def add_zeros(rdd):

    return rdd.map(lambda x: add_zeros_list(x))

## Grab index of file name
def get_index(line):

    index = [i for i, item in enumerate(line) if type(item) is str][0]

    return line[index], line[:(index - 1)] + line[(index + 1):]

## Extract file name from CSV
def pull_file_names(rdd, type=None):

    if type == "byte":

        return rdd.map(get_index)

    elif type == "asm":

        return rdd.map(get_index)

    else:
        raise Exception("INVALID TYPE OF FILE")

## Add classification to observations
def get_classes(dict_of_classes, rdd):

    return rdd.map(lambda x: (dict_of_classes[x[0]], x[1]))

## Shift classes to be compatible with MlLib
def shift_classes(rdd):

    return rdd.map(lambda x: (x[0] - 1, x[1]))

## Combine information from bytes and asm
def combine_cogroups(rdd):

    return rdd.map(lambda x: (x[0], x[1][0] + x[1][1]))

## Turn observation into MlLib LabeledPoint
def parsePoint(line):

    label = line[0]
    return LabeledPoint(label, line[1])

## Fit a MlLib random forest
def trainRandomForest(data):

    return RandomForest.trainClassifier(data, numClasses=9, categoricalFeaturesInfo={},
                                        numTrees=10, featureSubsetStrategy="auto",
                                        impurity='gini', maxDepth=30, maxBins=32)

def main(sc, path_to_asm, path_to_bytes, dictionary_of_classes):
    """
        This function takes a spark instance, a path to .asm csv's, a path to .bytes csv's, and
        a dictionary of classes. It cleans both csv's, combines them, and trains a
        9-way random forest
    """

    ## Read in csv's
    asm = sc.textFile(path_to_asm, 1000)
    bytes = sc.textFile(path_to_bytes, 1000)

    ## Split csv's by comma
    asm_csv = split_csv(asm)
    bytes_csv = split_csv(bytes)

    ## Replace null values with 0 and turn strings to floats
    asm_no_zeros = add_zeros(asm_csv)
    bytes_no_zeros = add_zeros(bytes_csv)

    ## Pull out file names
    asm_files = pull_file_names(asm_no_zeros, "asm")
    byte_files = pull_file_names(bytes_no_zeros, "byte")

    ## Merge files by file name
    combined = asm_files.cogroup(byte_files, 320)

    ## Unlist pyspark iterators
    vectors = combine_cogroups(combined)

    ## Replace file names with corresponding class
    classes = get_classes(dictionary_of_classes, vectors)
    shifted_classes = shift_classes(classes)

    ## Turn each feature into a LabeledPoint
    labeled_points = shifted_classes.map(parsePoint)

    labeled_points.saveAsTextFile("testrun.txt")

    ## Train a random forest
    tree = trainRandomForest(labeled_points)

    print tree

## This function returns a dictionary mapping file names to its class
def create_classes_dict(path_to_labels):

    response = urllib2.urlopen(path_to_labels)
    html = response.read()
    lines = html.split("\n")
    lines.pop(0)
    lines.pop(-1)

    classes = {}
    for el in lines:
        splits = el.split(",")
        classes[splits[0].strip('\"')] = int(splits[1])

    return classes

if __name__ == "__main__":
    path_to_asm_csvs = "path/to/asm/csv"
    path_to_bytes = "path/to/bytes/csv"
    path_to_labels = "path/to/train/labels"
    classes = create_classes_dict(pathtolabels)


    conf = SparkConf().setAppName("MyApp")
    conf.set("spark.executor.memory", "6g")
    sc = SparkContext(conf=conf)

    broadcastedVar = sc.broadcast(classes)

    main(sc, path_to_asm_csvs, path_to_bytes, broadcastedVar.value)

